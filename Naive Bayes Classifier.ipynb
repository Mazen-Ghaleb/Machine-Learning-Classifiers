{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c26eacee",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86bae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import util\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import doctest\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b507b0",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae958e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATUM_WIDTH = 0 # in pixels\n",
    "DATUM_HEIGHT = 0 # in pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670e5f8",
   "metadata": {},
   "source": [
    "# Module Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a43d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A datum is a pixel-level encoding of digits or face/non-face edge maps.\n",
    "\n",
    "# Digits are from the MNIST dataset and face images are from the \n",
    "# easy-faces and background categories of the Caltech 101 dataset.\n",
    "\n",
    "\n",
    "# Each digit is 28x28 pixels, and each face/non-face image is 60x74 \n",
    "# pixels, each pixel can take the following values:\n",
    "# 0: no edge (blank)\n",
    "# 1: gray pixel (+) [used for digits only]\n",
    "# 2: edge [for face] or black pixel [for digit] (#)\n",
    "\n",
    "# Pixel data is stored in the 2-dimensional array pixels, which\n",
    "# maps to pixels on a plane according to standard euclidean axes\n",
    "# with the first dimension denoting the horizontal and the second\n",
    "# the vertical coordinate:\n",
    "\n",
    "# 28 # # # #      #  #\n",
    "# 27 # # # #      #  #\n",
    "#  .\n",
    "#  .\n",
    "#  .\n",
    "#  3 # # + #      #  #\n",
    "#  2 # # # #      #  #\n",
    "#  1 # # # #      #  #\n",
    "#  0 # # # #      #  #\n",
    "#    0 1 2 3 ... 27 28\n",
    "\n",
    "# For example, the + in the above diagram is stored in pixels[2][3], or\n",
    "# more generally pixels[column][row].\n",
    "\n",
    "# The contents of the representation can be accessed directly\n",
    "# via the getPixel and getPixels methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30fffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datum:\n",
    "    # Create a new datum from file input (standard MNIST encoding).\n",
    "    def __init__(self, data, width, height):\n",
    "        DATUM_HEIGHT = height\n",
    "        DATUM_WIDTH= width\n",
    "        self.height = DATUM_HEIGHT\n",
    "        self.width = DATUM_WIDTH\n",
    "        if data == None:\n",
    "              data = [[' ' for i in range(DATUM_WIDTH)] for j in range(DATUM_HEIGHT)] \n",
    "        self.pixels = util.arrayInvert(convertToInteger(data)) \n",
    "\n",
    "    # Returns the value of the pixel at column, row as 0, or 1.\n",
    "    def getPixel(self, column, row):\n",
    "        return self.pixels[column][row]\n",
    "\n",
    "    # Returns all pixels as a list of lists.\n",
    "    def getPixels(self):\n",
    "        return self.pixels    \n",
    "\n",
    "    # Renders the data item as an ascii image.\n",
    "    def getAsciiString(self):\n",
    "        rows = []\n",
    "        data = util.arrayInvert(self.pixels)\n",
    "        for row in data:\n",
    "            ascii = map(asciiGrayscaleConversionFunction, row)\n",
    "            rows.append( \"\".join(ascii))\n",
    "        return \"\\n\".join(rows)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.getAsciiString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed8128",
   "metadata": {},
   "source": [
    "# Data processing, cleanup and display functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a9d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Reads n data images from a file and returns a list of Datum objects.\n",
    "#   (Return less then n items if the end of file is encountered).\n",
    "def loadDataFile(filename, n,width,height): \n",
    "    DATUM_WIDTH =width\n",
    "    DATUM_HEIGHT=height\n",
    "    fin = readlines(filename)\n",
    "    fin.reverse()\n",
    "    items = []\n",
    "    for i in range(n):\n",
    "        data = []\n",
    "        for j in range(height):\n",
    "            data.append(list(fin.pop()))\n",
    "        if len(data[0]) < DATUM_WIDTH-1:\n",
    "            # we encountered end of file...\n",
    "            print (\"Truncating at %d examples (maximum)\" % i)\n",
    "            break\n",
    "        items.append(Datum(data, DATUM_WIDTH, DATUM_HEIGHT))\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e5d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens a file or reads it from the zip archive data.zip\n",
    "def readlines(filename):\n",
    "      if(os.path.exists(filename)): \n",
    "        return [l[:-1] for l in open(filename).readlines()]\n",
    "      else: \n",
    "        print(os.getcwd())\n",
    "        z = zipfile.ZipFile('./data.zip')\n",
    "        liste= z.read(filename).decode(\"utf-8\").split(\"\\n\")\n",
    "        print(len(liste))\n",
    "        return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28327f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Reads n labels from a file and returns a list of integers.\n",
    "def loadLabelsFile(filename, n):\n",
    "    fin = readlines(filename)\n",
    "    labels = []\n",
    "    for line in fin[:min(n, len(fin))]:\n",
    "        if line == '':\n",
    "            break\n",
    "        labels.append(int(line))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8b567d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function for display purposes.\n",
    "def asciiGrayscaleConversionFunction(value):\n",
    "    if(value == 0):\n",
    "        return ' '\n",
    "    elif(value == 1):\n",
    "        return '+'\n",
    "    elif(value == 2):\n",
    "        return '#'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc9d1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function for file reading.\n",
    "def IntegerConversionFunction(character):\n",
    "    if(character == ' '):\n",
    "        return 0\n",
    "    elif(character == '+'):\n",
    "        return 1\n",
    "    elif(character == '#'):\n",
    "        return 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75339849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Helper function for file reading.\n",
    "def convertToInteger(data):\n",
    "    if type(data) != type([]):\n",
    "        return IntegerConversionFunction(data)\n",
    "    else:\n",
    "        return list(map(convertToInteger, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf2515",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78a7b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                +++++##+    \n",
      "        +++++######+###+    \n",
      "       +##########+++++     \n",
      "        #######+##          \n",
      "        +++###  ++          \n",
      "           +#+              \n",
      "           +#+              \n",
      "            +#+             \n",
      "            +##++           \n",
      "             +###++         \n",
      "              ++##++        \n",
      "                +##+        \n",
      "                 ###+       \n",
      "              +++###        \n",
      "            ++#####+        \n",
      "          ++######+         \n",
      "        ++######+           \n",
      "       +######+             \n",
      "    ++######+               \n",
      "    +####++                 \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "28\n",
      "28\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'getAsciiString', 'getPixel', 'getPixels', 'height', 'pixels', 'width']\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1, 1, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 1, 2, 2, 1, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "def _test():\n",
    "    doctest.testmod() # Test the interactive sessions in function comments\n",
    "    \n",
    "#     n = 451 # face data limit\n",
    "#     items = loadDataFile(\"./data/facedata/facedatatrain\", n,60,70)\n",
    "#     labels = loadLabelsFile(\"./data/facedata/facedatatrainlabels\", n)\n",
    "\n",
    "    n = 5000 # digit data limit\n",
    "    items = loadDataFile(\"./data/digitdata/trainingimages\", n,28,28)\n",
    "    labels = loadLabelsFile(\"./data/digitdata/traininglabels\", n)\n",
    "\n",
    "    for i in range(1):\n",
    "#         print (items[i].getAsciiString())\n",
    "        print (items[i])\n",
    "        print (items[i].height)\n",
    "        print (items[i].width)\n",
    "        print (dir(items[i]))\n",
    "        print (items[i].getPixels())\n",
    "        print (len(items[i].getPixels()))\n",
    "    \n",
    "_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20235f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pca_feature(feature):\n",
    "# #     print(feature)\n",
    "#     pca_reduction = PCA(n_components=1)\n",
    "#     pca_reduction.fit(feature)\n",
    "#     feature_pca = pca_reduction.transform(feature)\n",
    "#     print(feature_pca.shape)\n",
    "# #     new_feature = pca_reduction.inverse_transform(feature_pca)\n",
    "# #     print(new_feature)\n",
    "#     return feature_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bfab7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_amount = 5000\n",
    "training_labels = loadLabelsFile(\"./data/digitdata/traininglabels\", training_amount)\n",
    "training_items = loadDataFile(\"./data/digitdata/trainingimages\", training_amount,28,28)\n",
    "training_features= np.array([np.array(item.getPixels()).flatten() for item in training_items])\n",
    "# print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377c5304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_features))\n",
    "print(len(training_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c294c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 2 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 2 2 2 2 1 2 2 2 2 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 2 2 1 1 1 0 0 0 1 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 1 0 0\n",
      " 0 0 0 0 1 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 1 0 0 0 0 0 0 0 1 2 2 2 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 0 0 0 0 0 0 0 0 1 2 2 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 2 2 2 1 1 1 0 0 0 0 0 0 0 1 2 2 1 0 0 0 0 0 0 0 0 0 1 2 2 2 1 0 0 0 0 0\n",
      " 0 0 0 0 0 2 2 1 0 0 0 0 0 0 0 0 0 1 2 2 2 2 1 1 0 0 0 0 0 0 0 0 1 2 2 0 0\n",
      " 0 0 0 0 0 0 0 0 1 2 2 2 2 2 1 0 0 0 0 0 0 0 1 2 2 1 0 0 0 0 0 0 0 0 0 0 2\n",
      " 2 2 2 2 2 1 0 0 0 0 0 0 0 1 2 1 0 0 0 0 0 0 0 0 0 0 0 1 2 2 1 1 1 0 0 0 0\n",
      " 0 0 0 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 1 1 0 0 0 0 0 0 1 2 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 1 2 2 2 2 2 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2\n",
      " 2 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print ((training_features[1]))\n",
    "# print (training_features.shape[1])\n",
    "# print (training_features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4defe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Gaussian Classifier\n",
    "# model = MultinomialNB()\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(training_features,training_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3ef27",
   "metadata": {},
   "source": [
    "## Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c64dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictNaiveBayes(data, labels, dataName):\n",
    "    \n",
    "    prediction = np.array([])\n",
    "    correct_prediction = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        # Predict Output\n",
    "        predicted= model.predict([data[i]])[0]\n",
    "        np.append(prediction, predicted)\n",
    "        \n",
    "        if predicted == labels[i]:\n",
    "            correct_prediction += 1\n",
    "        \n",
    "    print (\"Accuracy of the Naive Bayes on the {} dataset is {} %\".format(dataName, correct_prediction*100/len(data)))\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9435cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_amount = 1000\n",
    "validation_labels = loadLabelsFile(\"./data/digitdata/validationlabels\", validation_amount)\n",
    "validation_items = loadDataFile(\"./data/digitdata/validationimages\", validation_amount, 28, 28)\n",
    "validation_features= np.array([np.array(item.getPixels()).flatten() for item in validation_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_amount = 1000\n",
    "test_labels = loadLabelsFile(\"./data/digitdata/testlabels\", validation_amount)\n",
    "test_items = loadDataFile(\"./data/digitdata/testimages\", validation_amount, 28, 28)\n",
    "test_features= np.array([np.array(item.getPixels()).flatten() for item in validation_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5677aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes on the Training dataset is 60.5 %\n",
      "Accuracy of the Naive Bayes on the Validation dataset is 55.6 %\n",
      "Accuracy of the Naive Bayes on the Test dataset is 9.3 %\n"
     ]
    }
   ],
   "source": [
    "training_prediction = predictNaiveBayes(training_features, training_labels, \"Training\")\n",
    "validation_prediction = predictNaiveBayes(validation_features,validation_labels, \"Validation\")\n",
    "test_prediction = predictNaiveBayes(test_features,test_labels, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "253d71b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "                            \n",
      "             ++###+         \n",
      "             ######+        \n",
      "            +######+        \n",
      "            ##+++##+        \n",
      "           +#+  +##+        \n",
      "           +##++###+        \n",
      "           +#######+        \n",
      "           +#######+        \n",
      "            +##+###         \n",
      "              ++##+         \n",
      "              +##+          \n",
      "              ###+          \n",
      "            +###+           \n",
      "            +##+            \n",
      "           +##+             \n",
      "          +##+              \n",
      "         +##+               \n",
      "         ##+                \n",
      "        +#+                 \n",
      "        +#+                 \n",
      "                            \n",
      "1000\n",
      "Predicted Value: 9\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print(test_items[n])\n",
    "print(len(test_items))\n",
    "\n",
    "# Predict Output\n",
    "predicted= model.predict([test_features[n]])[0]\n",
    "print (\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dc23644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 2\n",
    "# print(training_items[n])\n",
    "# print(len(training_items))\n",
    "\n",
    "# #Predict Output\n",
    "# predicted= model.predict([training_features[n]])[0]\n",
    "# print (\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a0b8d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1\n",
    "# print(validation_items[n])\n",
    "# print(len(validation_items))\n",
    "\n",
    "# #Predict Output\n",
    "# predicted= model.predict([validation_features[n]])[0]\n",
    "# print (\"Predicted Value:\", predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3614ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_reduction = PCA(n_components=1)\n",
    "# pca_reduction.fit(training_features)\n",
    "# training_features_pca = pca_reduction.transform(training_features)\n",
    "# new_training_features = pca_reduction.inverse_transform(training_features_pca)\n",
    "# training_prediction = predictNaiveBayes(new_training_features, training_labels, \"Training\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
